{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_MJx9xsehNJ"
      },
      "source": [
        "##Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfcjWJcvYPH-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeCbX_zgemDD"
      },
      "source": [
        "Importing DeepChem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGnYuwQ_VyRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e2f2fe-19c1-4110-e5ba-d6e864bca754"
      },
      "source": [
        "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
        "import conda_installer\n",
        "conda_installer.install()\n",
        "!/root/miniconda/bin/conda info -e\n",
        "!pip install --pre deepchem\n",
        "import deepchem as dc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3501  100  3501    0     0  18721      0 --:--:-- --:--:-- --:--:-- 18721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.7/site-packages to PYTHONPATH\n",
            "python version: 3.7.10\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "installing rdkit, openmm, pdbfixer\n",
            "added omnia to channels\n",
            "added conda-forge to channels\n",
            "done\n",
            "conda packages installation finished!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                  *  /root/miniconda\n",
            "\n",
            "Collecting deepchem\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/6e/1b8a3295f9eac3da3813b44300a68b108ef2f2c8060a9ce12863b30c13a2/deepchem-2.6.0.dev20210520034915-py3-none-any.whl (564kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.6.0.dev20210520034915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IA32th2j5bH"
      },
      "source": [
        "from deepchem.models.layers import GraphConv, GraphGather\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from deepchem.feat.mol_graphs import ConvMol"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeaKYgwRQBST"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljSegux1fRVf"
      },
      "source": [
        "class MyGraphConvModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyGraphConvModel, self).__init__()\n",
        "    self.gc1 = GraphConv(128, activation_fn=tf.nn.relu)\n",
        "\n",
        "    self.drop = layers.Dropout(rate=0.2)\n",
        "\n",
        "    self.gc2 = GraphConv(128, activation_fn=tf.nn.relu)\n",
        "\n",
        "    self.readout = GraphGather(batch_size=batch_size, activation_fn=tf.nn.relu)\n",
        "\n",
        "    self.dense1 = layers.Dense(256, activation=tf.nn.relu)\n",
        "\n",
        "    self.dense2 = layers.Dense(128, activation=tf.nn.relu)\n",
        "\n",
        "    self.dense3 = layers.Dense(64, activation=tf.nn.relu)\n",
        "\n",
        "    self.dense4 = layers.Dense(32, activation=tf.nn.relu)\n",
        "\n",
        "    self.dense5 = layers.Dense(1)\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    gc1_output = self.gc1(inputs)\n",
        "\n",
        "    drop_output = self.drop(gc1_output)\n",
        "\n",
        "    gc2_output = self.gc2([drop_output]+ inputs[1:])  \n",
        "\n",
        "    readout_output = self.readout([gc2_output] + inputs[1:])  \n",
        "\n",
        "    dense1_output = self.dense1(readout_output)\n",
        " \n",
        "    dense2_output = self.dense2(dense1_output)\n",
        "\n",
        "    dense3_output = self.dense3(dense2_output)\n",
        "    \n",
        "    dense4_output = self.dense4(dense3_output)\n",
        "\n",
        "    output = self.dense5(dense4_output)\n",
        "    return output\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb4Pq6TUabqF"
      },
      "source": [
        "#Preparing Data\n",
        "\n",
        "Models expect arrays of numbers as their inputs, not Python objects. We must convert the ConvMol objects into the particular set of arrays expected by the GraphConv, and GraphGather layers. Fortunately, the ConvMol class includes the code to do this, as well as to combine all the molecules in a batch to create a single set of arrays.\n",
        "\n",
        "The following code creates a Python generator that given a batch of data generates the lists of inputs, labels, and weights whose values are Numpy arrays. atom_features holds a feature vector of length 75 for each atom. The other inputs are required to support minibatching in TensorFlow. degree_slice is an indexing convenience that makes it easy to locate atoms from all molecules with a given degree. membership determines the membership of atoms in molecules (atom i belongs to molecule membership[i]). deg_adjs is a list that contains adjacency lists grouped by atom degree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmnpU9Zvi-nV"
      },
      "source": [
        "def data_generator(dataset, epochs=1):\n",
        "  for ind, (X_b, y_b, w_b, ids_b) in enumerate(dataset.iterbatches(batch_size, epochs,\n",
        "                                                                   deterministic=True, pad_batches=True)):\n",
        "    multiConvMol = ConvMol.agglomerate_mols(X_b)\n",
        "    inputs = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
        "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
        "      inputs.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
        "    \n",
        "    labels = [y_b]\n",
        "    weights = [w_b]\n",
        "    yield (inputs, labels, weights)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT5Y4MItuoJE"
      },
      "source": [
        "#Splitting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7k93CfWaoW8"
      },
      "source": [
        "splitters = ['random', 'scaffold', 'butina']\n",
        "batch = [50,100]\n",
        "learning = [0.0005, 0.0001]\n",
        "\n",
        "tasks, datasets, transformers = dc.molnet.load_bace_regression(featurizer='GraphConv', splitter=splitters[0])\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "\n",
        "batch_size = 50"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qr3ENt1alsM"
      },
      "source": [
        "#Fitting the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9mj1R3rtD4o",
        "outputId": "150de760-d592-43c3-98f4-160be2c6bfef"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
        "callback =  dc.models.ValidationCallback(data_generator(valid_dataset), 1000, metrics=metric)\n",
        "\n",
        "model = dc.models.KerasModel(MyGraphConvModel(), loss=dc.models.losses.L2Loss())\n",
        "losses = []\n",
        "model.fit_generator(data_generator(train_dataset, epochs=1000), all_losses= losses)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02930114507675171"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCHqWm9na4EU"
      },
      "source": [
        "#Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g4kz7AFFPAJ",
        "outputId": "ab85481c-9215-4ae8-eaa2-ab782b4bccf5"
      },
      "source": [
        "print(model.model.summary())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_graph_conv_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "graph_conv (GraphConv)       multiple                  204288    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "graph_conv_1 (GraphConv)     multiple                  346752    \n",
            "_________________________________________________________________\n",
            "graph_gather (GraphGather)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  32896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  2080      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  33        \n",
            "=================================================================\n",
            "Total params: 660,097\n",
            "Trainable params: 660,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRHwRseLa7a7"
      },
      "source": [
        "#Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUyN4Q3bZeHC",
        "outputId": "74bf762c-0de0-4247-fc56-3f00e41e6a1e"
      },
      "source": [
        "from deepchem.metrics import to_one_hot\n",
        "\n",
        "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
        "metric2 = dc.metrics.Metric(dc.metrics.rms_score)\n",
        "metric3 = dc.metrics.Metric(dc.metrics.mae_score)\n",
        "#square of Pearson correlation\n",
        "print('training set score:', model.evaluate_generator(data_generator(train_dataset), [metric], transformers))\n",
        "print('test set score L2:', model.evaluate_generator(data_generator(test_dataset), [metric], transformers))\n",
        "print('valid set score L2:', model.evaluate_generator(data_generator(valid_dataset), [metric], transformers))\n",
        "# root mean square error\n",
        "print('test set score rms:', model.evaluate_generator(data_generator(test_dataset), [metric2], transformers))\n",
        "# mean absolute error\n",
        "print('test set score mae:', model.evaluate_generator(data_generator(test_dataset), [metric3], transformers))\n",
        "# mean squared error\n",
        "print('training set mse:', model.evaluate_generator(data_generator(train_dataset), [dc.metrics.Metric(dc.metrics.mean_squared_error)], transformers))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set score: {'pearson_r2_score': 0.988019369784596}\n",
            "test set score L2: {'pearson_r2_score': 0.7288292436615328}\n",
            "valid set score L2: {'pearson_r2_score': 0.46301749258593017}\n",
            "test set score rms: {'rms_score': 0.895647689016439}\n",
            "test set score mae: {'mae_score': 0.7028270603231244}\n",
            "training set mse: {'mean_squared_error': 0.023010553676752327}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qcRCRDyDsCh"
      },
      "source": [
        "#Build In"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcBnp2oYCS34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea977cf8-fee0-4c29-b9af-fac392fb23b2"
      },
      "source": [
        "model = dc.models.GraphConvModel(1, mode='regression')\n",
        "model.fit(train_dataset, nb_epoch=100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.038815505504608154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnDedwUNCkE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db841ac4-18a3-4c9c-b3ef-3d468fd2d71b"
      },
      "source": [
        "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
        "print('Training set score:', model.evaluate(train_dataset, [metric], transformers))\n",
        "print('Test set score:', model.evaluate(test_dataset, [metric], transformers))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: {'pearson_r2_score': 0.9610046181403874}\n",
            "Test set score: {'pearson_r2_score': 0.5832503339189358}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}